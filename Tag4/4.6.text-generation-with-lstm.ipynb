{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "[...]\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a \n",
    "language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this \n",
    "example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model \n",
    "we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the \n",
    "English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = tensorflow.keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will extract partially-overlapping sequences of length `maxlen`, one-hot encode them and pack them in a 3D Numpy array `x` of \n",
    "shape `(sequences, maxlen, unique_characters)`. Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot \n",
    "encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/2lmpnq392gd70tbtk1y3fs9nxm_fkt/T/ipykernel_13618/2500304246.py:26: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "/var/folders/gd/2lmpnq392gd70tbtk1y3fs9nxm_fkt/T/ipykernel_13618/2500304246.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Our network is a single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters. But let us note that \n",
    "recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in \n",
    "recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:16:26.203104: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phbo/opt/miniconda3/lib/python3.8/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tensorflow.keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "* 1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "* 2) Reweighting the distribution to a certain \"temperature\"\n",
    "* 3) Sampling the next character at random according to the reweighted distribution\n",
    "* 4) Adding the new character at the end of the available text\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, \n",
    "and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures \n",
    "after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of \n",
    "temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1565/1565 [==============================] - 186s 118ms/step - loss: 1.9648\n",
      "--- Generating with seed: \"utbreak and\n",
      "display as the \"salvation army\"--if it be a ques\"\n",
      "------ temperature: 0.2\n",
      "utbreak and\n",
      "display as the \"salvation army\"--if it be a question of the such onery a fing the sentiment of the least of the sure of the suppose of the reasing the sentime and the superition of the suppineres and subject of the sumpired to the supposing the supporing and suppirite of a coures of the sumpation of the suppicious the sentiment of the subtime and so will the supposing the obler to be of a coure of the suppose and the sense and suppired to the s\n",
      "------ temperature: 0.5\n",
      "f a coure of the suppose and the sense and suppired to the sufferings in the restined and suppirent to caun on a cause of all the conterfuces of even the enough of resurting the subting. they is the obler of should in this resire the good of a cention of mears and suspices and sure enture to the sentime and in\n",
      "the chuist and sime even the hists to existial, this is the lear he consequence of more and the learation of maninisher in the most and condinion in\n",
      "------ temperature: 1.0\n",
      "and the learation of maninisher in the most and condinion in hij sentable reyige in time--the be wlike to doestly and still the senst irirnomoles of rage led and be now--the by other suysaldy\n",
      "(arrileding\n",
      "it was\n",
      "sundiving anbestre. they are our will facr disipliged are a suberopable to the a to freentclommatisy. an obade\n",
      "conscienced to manination--hore are to to subler must of him orwords on ir collaged the our will,goor disgredernt are for exilince of\n",
      "the \n",
      "------ temperature: 1.2\n",
      "laged the our will,goor disgredernt are for exilince of\n",
      "the midbordois such sthom\n",
      "tastoupofuricias to they knows, appace a nof ochsmo srain to a de in itselfs\n",
      "chomd\n",
      "but deoaby\n",
      "worning, a very\n",
      "vaniener, and interxistion to ress-aidnors \"or frord\n",
      "differege aftaliced in the wandires--artes. and, superxe, real in tinvisk or. -hat for meknond to with the\n",
      "dount orsolinf-every mesticati.y, wicl\n",
      "maniner bling clomsequory contion: the yem, hand krodime, dear: and\n",
      "s\n",
      "epoch 2\n",
      "1565/1565 [==============================] - 183s 117ms/step - loss: 1.6117\n",
      "--- Generating with seed: \"nunciation of his thirst for vengeance indifferently. he cra\"\n",
      "------ temperature: 0.2\n",
      "nunciation of his thirst for vengeance indifferently. he craith, and the godish of the sense of the art of the some of the sense, and something of the sense of the sense of the most something to the self-dorto and something of the all the artists of the sense of the self the find to the world of the god, and the perhaps the most and in the same of the sense of the god, and something of the self to something of the same of the sense of the sense of the all \n",
      "------ temperature: 0.5\n",
      " something of the same of the sense of the sense of the all good and the god. ever the most contempt of the wholl in the destruction of the art of the most by the all of a contleciate of the enishing and intendence of the still to the find to an all it is this fortural to something of the self-to the philosophy strange and most cases it is a some of necessary, which and of the world and all the look a perhaps\n",
      "intention of the despect of the same of the des\n",
      "------ temperature: 1.0\n",
      "ok a perhaps\n",
      "intention of the despect of the same of the dest-nationle is a jedismentaod of its; such do men and destrest to long--simil of a\n",
      "dowx and\n",
      "suacuption, it would life\n",
      "and is be of their sole good graile with other worldiess. our of all indecired not, something his ityer of gordered for unletion he apcours,\n",
      "the .or\n",
      "religions contempt of all\n",
      "the temple would conity of hymerulthcy,-frand the uncertopic oolwan, fight quic, their allopinable man for t\n",
      "------ temperature: 1.2\n",
      "e uncertopic oolwan, fight quic, their allopinable man for thereborder upon our the sagr)\n",
      "of more alse, at symparlite,.\n",
      "\n",
      "139\n",
      "\n",
      "=  otalctifird a xcard,\n",
      "to more fade, ages, nor c astly self nothom lofuallyboun--found and slesulbileti's\n",
      "much mefeenesty of the unbeens. us\n",
      "\"lade our \"-llaming of tionas. ever d)ing). -) litted cast philosophy., and nowind, lise shindous \"quiticaulat veryonedhy,\n",
      "it is whenge seok affel consolish.\n",
      "to never\n",
      "guarnwie\n",
      "cause asce, \"kno\n",
      "epoch 3\n",
      "1565/1565 [==============================] - 199s 127ms/step - loss: 1.5238\n",
      "--- Generating with seed: \"r, what is \"explained\"? only that which can be seen and\n",
      "felt\"\n",
      "------ temperature: 0.2\n",
      "r, what is \"explained\"? only that which can be seen and\n",
      "felted the most be a soul and sense the most be the sere the conditional more a more also a matter the conduct and sense the most conscience and the are a soul the most be been a something and strength and more the more also a secorther and in the sere the conditional are a soul and self-something the serpones to the same also the most strict, and serious and self-life and sense the most strength and \n",
      "------ temperature: 0.5\n",
      ", and serious and self-life and sense the most strength and present have ween and must, as it is the most sick, and friending become and speak and self-decietion of the rested from the understand to the strength, and always wells and contracter and are not bade when the strengt of serious of the present in preture to the call is the more after the conditional then hard percain in the serphater and most called\n",
      "grame are something the one it is still the sen\n",
      "------ temperature: 1.0\n",
      " most called\n",
      "grame are something the one it is still the sense as comancely, we are enlighand--with regard in a higherr, for ofclurates fnordy are that one who are\n",
      "himpecr, though\"pay! they upon the prevoctly constanture of the cillop.\" alt resten passion of menner at instrekn: and twoss, as\n",
      "ropted to themordly assemied of all tray is well to\n",
      "all, becomition and serpaines be\"\n",
      "inssablekefors, masterstoxe, for good asmitive and degree thinking and\n",
      "deality up\n",
      "------ temperature: 1.2\n",
      "rstoxe, for good asmitive and degree thinking and\n",
      "deality upon the hig\n",
      "those, \"this\n",
      "disc\"tume with; dideslefje mais, eventry\n",
      "bro,\n",
      "inavourondud and,\n",
      "if\n",
      "now, whic  sain\n",
      "is the themselli hare sometwagry, a prciose, is also\n",
      "bling emil inourn throrabad. free of spanity of a\n",
      "sicked\n",
      "byting, troui\n",
      "strengly conscieatehed, those amplice of amperalet beterno, aursely absuist ry!--religions\n",
      "as not, hymans make a\n",
      "kind,\n",
      "intory. wh waen deatisming:\n",
      "eyes if an ads?\n",
      "would \n",
      "epoch 4\n",
      "1565/1565 [==============================] - 190s 121ms/step - loss: 1.4789\n",
      "--- Generating with seed: \". supposing,\n",
      "in effect, that man is not just the \"measure of\"\n",
      "------ temperature: 0.2\n",
      ". supposing,\n",
      "in effect, that man is not just the \"measure of the same the sense of the sense and consequence of the spirits of the same the spirits and the sense of the same the souls of the spirits of the same the spirits of the sense of the same the consequence of the same the sense of the same the same the sense of the same the propect to be a soul and soul and the man is the consequence of a consider to the superiority in the science and soul and the s\n",
      "------ temperature: 0.5\n",
      "onsider to the superiority in the science and soul and the seriousness, and promiced the feelings, on the faith to stands of men best decider and short sort and condect that the means of the precisely and about the new that the one\n",
      "to at his condect which the schoolaring to the fair in the strong of the fathers in the sense and to stoped is the scientific concerning to the should would to religion as its own devilowness of a soe is the under to so under th\n",
      "------ temperature: 1.0\n",
      " as its own devilowness of a soe is the under to so under the dole, mepraccy as i man superiint. i man not havatiet and proprided badicury, this themselves which.\n",
      "\n",
      "\n",
      "other own happhtyan nomies strange. psositions2(\". stell no he anmying, evil\n",
      "in sorier. through steld that has tere, and oee's needs something led no religionly onestical, bot that what \n",
      "keekser\n",
      "predise sambists the artifice, the orcerys, he condition may rires, church. indicencl is mecallartes\n",
      "------ temperature: 1.2\n",
      "ys, he condition may rires, church. indicencl is mecallartes\n",
      "even of humine of it is is\n",
      "consequent of which in the god in her but the thus opmons\n",
      "as forahic ncit is to strong she man gave. the so trutile-suched to a\" recognived nothing, the fribth,\" and an freamfran oniged? which is difications,\"\n",
      "sowient the \"soctors. from soursic veptious, mane, awaken grimarityed antasses, liker exist and demoded at the fatiling transcic. to call thfurssess and\n",
      "the tagen\n",
      "epoch 5\n",
      "1565/1565 [==============================] - 146s 93ms/step - loss: 1.4496\n",
      "--- Generating with seed: \"he antagonism between the\n",
      "specialties of science and philoso\"\n",
      "------ temperature: 0.2\n",
      "he antagonism between the\n",
      "specialties of science and philosophers of the world and the desire of the super the spirit the pression of the strong to the spirit and disposing of the same the same the sense of the same the personal profound to the spirit and the spirit and such a proposed to the same the pression of the constrative the sense of the same the pression of the same a probably the same the sense of the has the sense of the pression of the same the\n",
      "------ temperature: 0.5\n",
      "e sense of the has the sense of the pression of the same the most devilsction strong which is concerning the general histhere of the most such a period of the sympathy of the most words that the sense and spirit and eventure, such a things so revelope, which the himself in the spirit at the strength, the good distunce and logical being the spirit would be point to desires for new does in the\n",
      "most so more influent end the wholous to the discoursed to manact\n",
      "------ temperature: 1.0\n",
      "so more influent end the wholous to the discoursed to manacten, unstions with the work of the sufferingly to the smynes more wart species, states lead, among these stept, for\n",
      "an the lare\n",
      "and the most permatiralwipidion and unholtionaliticted \"expedien, have cooring be simpvable in soul should be a\n",
      "ultradagine, which the upinso aupation and evil, and spirit. as a unjutt, which there sharse thealck to last the\n",
      "a means germasus\n",
      "instance, \"world now the ventur\n",
      "------ temperature: 1.2\n",
      "to last the\n",
      "a means germasus\n",
      "instance, \"world now the venture which a would rell some eternative of whaten xquedet kind himself--peroucs, sought, if\n",
      "the  am with a question\n",
      "it volund comparative tendernfilating--let i thull\n",
      "dide whith\n",
      "it precised just and seem to dells bace\") howeve opinion.\n",
      "so which is: by na stengoal. the by\n",
      "only but any\n",
      "immonstal\n",
      "pisimatial 'nely combide. it is hart of a wouling ratus, editilyoun. that a \"thominguses what a sext\n",
      "of cult\n",
      "epoch 6\n",
      "1565/1565 [==============================] - 162s 104ms/step - loss: 1.4276\n",
      "--- Generating with seed: \"d who knows but in all great\n",
      "instances hitherto just the sam\"\n",
      "------ temperature: 0.2\n",
      "d who knows but in all great\n",
      "instances hitherto just the same the sense of the said and such a more desire the sentiment of the most desire and still the sense of the same the more and such and the sense of the gois a consider desire the sense of the sentiment of the most desire of the subjection of the sentiment of the same the most decention of the strong in the same the sufficient to a more desire the most destruction of the consequently condect of the \n",
      "------ temperature: 0.5\n",
      "ire the most destruction of the consequently condect of the same many such ancentical of the intellect of the most condition to the does no other in the most forting of the most surpons to live the simply, and spirit of his more existence by him in the desire some have the more disporited to be reading of still lead to him we may be takes the stronger, in self-consider of the most surity and cause the sublime the sense and say a profound to all which seems\n",
      "------ temperature: 1.0\n",
      " the sublime the sense and say a profound to all which seems are\n",
      "masiditagion to be wholly fortor\n",
      "yetne, tall too philosophers--\"by the whole fraincy are earis \"naturalize of the earth or which learnt prised my coestience of mused in iis. in with you it, as\n",
      "down, the still the hat above rative with too the inally ventering him a prosumdions--natural made nothine of the utselisistity for everyrly ,   new--wish, fortion responssion or to\n",
      "masparts heremoves a\n",
      "------ temperature: 1.2\n",
      "   new--wish, fortion responssion or to\n",
      "masparts heremoves and\n",
      ", the clissses,\n",
      "poin unmis disting,\n",
      "belonged are made were name ititords, \n",
      "man in still lamoue althing problems, my comes is at proleng for told,\n",
      "ngimrs it coold--im, theo-alse? the french objectity of agciors which--isf xif,\n",
      "wollednes roes is philos at little delube's existenchable: this dee?s\n",
      "usecribed of men euthinknce, faith thoughment, when\n",
      "it indeed the caus. the beliturines, whereottainl\n",
      "epoch 7\n",
      "1565/1565 [==============================] - 165s 105ms/step - loss: 1.4109\n",
      "--- Generating with seed: \"or the chapter: \"morals as timidity.\"\n",
      "\n",
      "199. inasmuch as in a\"\n",
      "------ temperature: 0.2\n",
      "or the chapter: \"morals as timidity.\"\n",
      "\n",
      "199. inasmuch as in a strong and the sense of the saint to the subsistary and the sense and the sense and and as the sense and the desire to the saints of the sense and the sense to the sense of the saints of the great such a souls of the being of the sense of the sense the sense and the way and the self-considered and the self-concerning the more the sense the sense to the reason to the conscience of the saint of the\n",
      "------ temperature: 0.5\n",
      "he sense to the reason to the conscience of the saint of the soul and he will the \"incondition of its also the promised in the commander of the conscience of the artistic man are such all the same also which the deportunes. the action, the more position in the every\n",
      "science and and the sinless and in the make one cause of the whole become soul as he means and seems to be all in the more for the arrow with the goes has been the saints the states of god, and\n",
      "------ temperature: 1.0\n",
      "row with the goes has been the saints the states of god, and that worldly amoegly and to their malamin glous, measures exchablements, a high homal begoeling the exiltency to the unccean for it when it goal resolution and exercise of life-arts to\n",
      "make magity, and mandity\"--but the compalition rescendent, which impostloy, to one's abours\n",
      "of man deceive\n",
      "his materily antartments of famouncing, these more loarncy as other\n",
      "roly of the qualities which ightual alm\n",
      "------ temperature: 1.2\n",
      "ore loarncy as other\n",
      "roly of the qualities which ightual almost-excessed, by much impous. in glepary\n",
      "of the inmostary andworten stregrs\n",
      "teacht to\n",
      "we old wust, alodous by all understand true pleastic subsricbe.\n",
      "could to suf\n",
      "rades. not to be tet, on even which\n",
      "but to ruled tu gy againathosith--thatinasy himself i, a demortud, among thouds, what makes to loes depthiud\n",
      "to chinster as odeen canurek knows\n",
      "etiekstly-so in its fe\"ther? \"inschiongedity ohgandotomed\n",
      "epoch 8\n",
      "1565/1565 [==============================] - 145s 93ms/step - loss: 1.3974\n",
      "--- Generating with seed: \"pon\n",
      "much that formerly inspired dread. one would be rid of t\"\n",
      "------ temperature: 0.2\n",
      "pon\n",
      "much that formerly inspired dread. one would be rid of the constant the are as the experience, and all the strength in the same the same time in the most spirit and always and also a man is the conscience of the same time in the spirit and in the same the present and the desire the constant the same the present and such a man is a personal the conscience of the same time of the same to the interrisibity of the same at present and and the same one of th\n",
      "------ temperature: 0.5\n",
      "errisibity of the same at present and and the same one of the hat the great prevently and one of the misund will as the intellect and one of the men who has been deceived the fact and or proves that the sacrifice in the spirit, has he count and conducts in the most appearance, the most what one should not predimination of its general to the discisery to the present seem that in the precisely and conscience and the are in the detariities and the whole of th\n",
      "------ temperature: 1.0\n",
      "onscience and the are in the detariities and the whole of the aw shun, whereshing that the firs that a . but theny definits and ximself\", faith regard, the things thereof like is generals, but by contrarf, who are are ae \n",
      "the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colord by pretentificam foothin discovers whether moral understance: promage take the suffering nertits carriness, they innate turk in the value, are its because the rendovs,\n",
      "and wholly, wishented have to plented--and not be simply ac\n",
      "------ temperature: 1.2\n",
      "\n",
      "and wholly, wishented have to plented--and not be simply acts for demytcormsain of to inveed free to a\n",
      "paisoul of nature be.ce with social\n",
      "byethe,\n",
      "stpononeshy in rapswish of\n",
      "that timan, in ordernely the bever mateswerest, by malt arists a system and taste operated\"\n",
      "efor orceablly iuse in the goinguterd orification rised bies. upet\n",
      "doped some depressate estamoung--perteild, fens: became red into the sapects of wishes, resitecesk heilence. who stand therelf\n",
      "epoch 9\n",
      "1565/1565 [==============================] - 132s 84ms/step - loss: 1.3859\n",
      "--- Generating with seed: \"be off--and\n",
      "not back!\n",
      "\n",
      "11. it seems to me that there is ever\"\n",
      "------ temperature: 0.2\n",
      "be off--and\n",
      "not back!\n",
      "\n",
      "11. it seems to me that there is ever the consisted to the possible to the consisted to the moral contempted to an exception of the possible to the sense of the superiation of the belief the a period and souls of the consequence of the same and the sense of the same disposition of the possible to a souls of the reason of the present contrary of the same and the possible to the sense of mankind to the consisted to the fact to the poss\n",
      "------ temperature: 0.5\n",
      "he sense of mankind to the consisted to the fact to the possible to the contlive and sumbing of some ourselves, and subtile of the possible of pleasing the greated that we have distrust and presence of men, as a disposition and souls and origin of things in the strength and the moral possess of skepticism to the present communical conscious contrary is a period will be former and still necessary to be partially almost all the greated to his false contrary,\n",
      "------ temperature: 1.0\n",
      "o be partially almost all the greated to his false contrary, not contcrioly of mecapahicistnessfulestory\n",
      "in merel--beagering subsequence of destruesting, is as a worker, and autom of earliest of thing of the result, adchoucces is tentred-let the sublimatic to the, the ways here\n",
      "and roth him seems general in the same display and destinated of sland, be also also entour donene?s\n",
      "manven the such a mutficate\"\n",
      "infeaince and believes withees or a most \"also spec\n",
      "------ temperature: 1.2\n",
      "tficate\"\n",
      "infeaince and believes withees or a most \"also specials, and alsolly of\n",
      "exis this dedour\n",
      "age sons more viw)-not of mankind remain impul vay in th, but discles subsist-live andavegande aince as outdest of\n",
      "this\n",
      "andver pieed formen thought, the last\n",
      "yer struggle,d--in youthf,r is no pleasing. botad to be!\n",
      "                        makes.\n",
      "\n",
      "12th que! not\n",
      "like in a grade reason distunge, make as night the . in with\n",
      "someat usbingratest\n",
      "melations out.=--mor\n",
      "epoch 10\n",
      " 655/1565 [===========>..................] - ETA: 1:22 - loss: 1.3552"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gd/2lmpnq392gd70tbtk1y3fs9nxm_fkt/T/ipykernel_13618/3298770539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Fit the model for 1 epoch on the available training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     model.fit(x, y,\n\u001b[0m\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               epochs=1)\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, a low temperature results in extremely repetitive and predictable text, but where local structure is highly realistic: in \n",
    "particular, all words (a word being a local pattern of characters) are real English words. With higher temperatures, the generated text \n",
    "becomes more interesting, surprising, even creative; it may sometimes invent completely new words that sound somewhat plausible (such as \n",
    "\"eterned\" or \"troveration\"). With a high temperature, the local structure starts breaking down and most words look like semi-random strings \n",
    "of characters. Without a doubt, here 0.5 is the most interesting temperature for text generation in this specific setup. Always experiment \n",
    "with multiple sampling strategies! A clever balance between learned structure and randomness is what makes generation interesting.\n",
    "\n",
    "Note that by training a bigger model, longer, on more data, you can achieve generated samples that will look much more coherent and \n",
    "realistic than ours. But of course, don't expect to ever generate any meaningful text, other than by random chance: all we are doing is \n",
    "sampling data from a statistical model of which characters come after which characters. Language is a communication channel, and there is \n",
    "a distinction between what communications are about, and the statistical structure of the messages in which communications are encoded. To \n",
    "evidence this distinction, here is a thought experiment: what if human language did a better job at compressing communications, much like \n",
    "our computers do with most of our digital communications? Then language would be no less meaningful, yet it would lack any intrinsic \n",
    "statistical structure, thus making it impossible to learn a language model like we just did.\n",
    "\n",
    "\n",
    "## Take aways\n",
    "\n",
    "* We can generate discrete sequence data by training a model to predict the next tokens(s) given previous tokens.\n",
    "* In the case of text, such a model is called a \"language model\" and could be based on either words or characters.\n",
    "* Sampling the next token requires balance between adhering to what the model judges likely, and introducing randomness.\n",
    "* One way to handle this is the notion of _softmax temperature_. Always experiment with different temperatures to find the \"right\" one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bewertungslink f√ºr dieses Seminar](https://ratings.gfu.cloud/form.html?h=62914f9a3ad5aa10a1ddd82b1ce8181c5bde9ac2bb5b4154cafe5b1da373b3d4&type=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
